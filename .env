# server
HOST = 127.0.0.1
PORT = 1337

# model
MODEL_PATH = "..\llama\huggingface\Llama-2-7b-chat-hf"
LOAD_IN_8BIT = False
DEVICE = cuda

# prompts
MAX_MAX_NEW_TOKENS = 2048
DEFAULT_MAX_NEW_TOKENS = 1024
MAX_INPUT_TOKEN_LENGTH = 4096
DEFAULT_TEMPERATURE = 0.8
DEFAULT_TOP_K = 50
DEFAULT_TOP_P = 0.95
DEFAULT_SYSTEM_PROMPT = "Your name is Nova. You are a a helpful assistant."

